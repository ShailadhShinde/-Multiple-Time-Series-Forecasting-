{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"ceacd054-9ae9-4945-9a3d-e5462b4554e9","_cell_guid":"50076e06-7435-4ba5-a413-555201b73e60","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-01T14:40:27.991984Z","iopub.execute_input":"2024-08-01T14:40:27.992457Z","iopub.status.idle":"2024-08-01T14:40:28.991348Z","shell.execute_reply.started":"2024-08-01T14:40:27.992419Z","shell.execute_reply":"2024-08-01T14:40:28.990288Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\ntrain = pd.read_csv(r\"/kaggle/input/store-sales-time-series-forecasting/train.csv\",\n                   usecols=[1,2,3,4,5],parse_dates=['date'],\n                   converters={'sales': lambda u: np.log1p(float(u)) if float(u) > 0 else 0},\n                  )\ntest = pd.read_csv(r\"/kaggle/input/store-sales-time-series-forecasting/test.csv\",\n                  usecols=[1,2,3,4],parse_dates=['date']\n                  )","metadata":{"_uuid":"4d26509b-9840-4b29-900a-bd59c1e0abf3","_cell_guid":"ed4ec356-94c2-423a-8dd1-1e4f28cc3c1f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-01T14:40:31.705512Z","iopub.execute_input":"2024-08-01T14:40:31.706090Z","iopub.status.idle":"2024-08-01T14:40:38.576918Z","shell.execute_reply.started":"2024-08-01T14:40:31.706054Z","shell.execute_reply":"2024-08-01T14:40:38.575804Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"promo_train=train.set_index(['store_nbr','family','date'])['onpromotion'].unstack().fillna(0)\npromo_test=test.set_index(['store_nbr','family','date'])['onpromotion'].unstack().fillna(0)\npromo=pd.concat([promo_train,promo_test],axis=1)\n\nsales_train=train.set_index(['store_nbr','family','date'])['sales'].unstack().fillna(0)\n\nfamily=sales_train.groupby('family')[sales_train.columns].sum()\nfamily_promo=promo.groupby('family')[promo.columns].sum()\n\nstore_family=sales_train.reset_index()\nstore_family_index=store_family[['store_nbr','family']]\nstore_family=store_family.groupby(['store_nbr','family'])[sales_train.columns].sum()\n\nstore_family_promo=promo.reset_index()\n\nstores = pd.read_csv(r\"/kaggle/input/store-sales-time-series-forecasting/stores.csv\").set_index('store_nbr')\nle = LabelEncoder()\n\nstores['city'] = le.fit_transform(stores['city'].values)\nstores['state'] = le.fit_transform(stores['state'].values)\nstores['type'] = le.fit_transform(stores['type'].values)\n\nstores=stores.reindex(sales_train.index.get_level_values(0))\n\n#promo=pd.concat([promo_train,promo_test],axis=1)\n#del promo_train,promo_test\n\nfirst_date = '2013-01-01'\nval_start=pd.to_datetime('2017-7-25')\n\ntest_start=pd.to_datetime('2017-8-16')","metadata":{"_uuid":"2cc55c0a-3169-4ac8-9088-a8ff12494e7c","_cell_guid":"a3ac93d7-7237-4cab-a434-9c20966d9ad4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-01T14:40:38.581218Z","iopub.execute_input":"2024-08-01T14:40:38.581571Z","iopub.status.idle":"2024-08-01T14:40:42.298115Z","shell.execute_reply.started":"2024-08-01T14:40:38.581541Z","shell.execute_reply":"2024-08-01T14:40:42.296982Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def get_timespan(df,date,minusdays,periods,freq='D'):\n    return df[pd.date_range(date-timedelta(days=minusdays) ,periods=periods, freq=freq)]","metadata":{"_uuid":"80b53a26-2b2e-4bb1-82d5-a400b4a40624","_cell_guid":"275b551e-b3ec-4990-80da-5dfb861effd7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-01T14:40:46.977416Z","iopub.execute_input":"2024-08-01T14:40:46.977948Z","iopub.status.idle":"2024-08-01T14:40:46.984083Z","shell.execute_reply.started":"2024-08-01T14:40:46.977904Z","shell.execute_reply":"2024-08-01T14:40:46.982840Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(df,promo,date,columnname=None,is_train=True):\n    \n   \n    X={\n        \"promo_3_bef\": get_timespan(promo, date, 3, 3).sum(axis=1).values,         \n        \"promo_7_bef\": get_timespan(promo, date, 7, 7).sum(axis=1).values,         \n        \"promo_14_bef\": get_timespan(promo, date, 14, 14).sum(axis=1).values,         \n        \"promo_60_bef\": get_timespan(promo, date, 60, 60).sum(axis=1).values,\n        \"promo_140_bef\": get_timespan(promo, date, 140, 140).sum(axis=1).values,\n        \"promo_3_aft\": get_timespan(promo, date + timedelta(days=16), 15, 3).sum(axis=1).values,\n        \"promo_7_aft\": get_timespan(promo, date + timedelta(days=16), 15, 7).sum(axis=1).values,\n        \"promo_14_aft\": get_timespan(promo, date + timedelta(days=16), 15, 14).sum(axis=1).values,\n        \"promo_mean_3_bef\": get_timespan(promo, date, 3, 3).mean(axis=1).values,         \n        \"promo_mean_7_bef\": get_timespan(promo, date, 7, 7).mean(axis=1).values,         \n        \"promo_mean_14_bef\": get_timespan(promo, date, 14, 14).mean(axis=1).values,         \n        \"promo_mean_60_bef\": get_timespan(promo, date, 60, 60).mean(axis=1).values,\n        \"promo_mean_140_bef\": get_timespan(promo, date, 140, 140).mean(axis=1).values,\n        \"promo_mean_3_aft\": get_timespan(promo, date + timedelta(days=16), 15, 3).mean(axis=1).values,\n        \"promo_mean_7_aft\": get_timespan(promo, date + timedelta(days=16), 15, 7).mean(axis=1).values,\n        \"promo_mean_14_aft\": get_timespan(promo, date + timedelta(days=16), 15, 14).mean(axis=1).values,\n        \n    }\n    for i in [3,7,14,30,60,140]:\n        tmpdf=get_timespan(df,date + timedelta(days=-7),i,i)\n        X['diff_%s_mean_2' %i]=tmpdf.diff(axis=1).mean(axis=1).values\n        X['mean_%s_decay_2' % i] = (tmpdf * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n        X['mean_%s_2' % i] = tmpdf.mean(axis=1).values\n        X['median_%s_2' % i] = tmpdf.median(axis=1).values\n        X['min_%s_2' % i] = tmpdf.min(axis=1).values\n        X['max_%s_2' % i] = tmpdf.max(axis=1).values\n        X['std_%s_2' % i] = tmpdf.std(axis=1).values\n    \n    for i in [3,7,14,30,60,140]:\n        tmpdf=get_timespan(df,date,i,i)\n        X['diff_%s_mean' %i]=tmpdf.diff(axis=1).mean(axis=1).values\n        X['mean_%s_decay' % i] = (tmpdf * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n        X['mean_%s' % i] = tmpdf.mean(axis=1).values\n        X['median_%s' % i] = tmpdf.median(axis=1).values\n        X['min_%s' % i] = tmpdf.min(axis=1).values\n        X['max_%s' % i] = tmpdf.max(axis=1).values\n        X['std_%s' % i] = tmpdf.std(axis=1).values\n    \n    X=pd.DataFrame(X)\n    \n    if is_train:\n        y=df[pd.date_range(date,periods=16)].values\n        return X,y\n    \n    if columnname is not None:\n        X.columns = ['%s_%s' % (columnname, c) for c in X.columns]\n\n   # time.sleep(80)\n    return X","metadata":{"_uuid":"5a519db7-666c-41c5-b861-047a316789ba","_cell_guid":"1c0e4fc9-3a82-400e-91a4-2b0e8f4867c3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-01T14:40:42.311135Z","iopub.execute_input":"2024-08-01T14:40:42.311598Z","iopub.status.idle":"2024-08-01T14:40:42.333410Z","shell.execute_reply.started":"2024-08-01T14:40:42.311559Z","shell.execute_reply":"2024-08-01T14:40:42.332102Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"val_x,val_y=prepare_dataset(store_family,store_family_promo,val_start,columnname='store_family')\n#val.index=store_family.index\n#val=val_2.reindex(store_family_index.set_index(['store_nbr','family']).index).reset_index(drop=True)\n\n\nval_1=prepare_dataset(family,family_promo,val_start,columnname='family',is_train=False)\nval_1.index=family.index\nval_1=val_1.reindex(sales_train.index.get_level_values(1)).reset_index(drop=True)\n\nvalidation=pd.concat([val_x,val_1,stores.reset_index()],axis=1).fillna(0)\ndel val_1,val_x\n\ntest_1=prepare_dataset(store_family,store_family_promo,test_start,columnname='store_family',is_train=False)\n#test_2.index=store_family.index\n#test_2=test_2.reindex(store_family_index.set_index(['store_nbr','family']).index).reset_index(drop=True)\n\ntest_2=prepare_dataset(family,family_promo,test_start,columnname='family',is_train=False)\ntest_2.index=family.index\ntest_2=test_2.reindex(sales_train.index.get_level_values(1)).reset_index(drop=True)\n\n\ntest=pd.concat([test_1,test_2,stores.reset_index()],axis=1).fillna(0)\ndel test_1,test_2","metadata":{"_uuid":"109c0cb4-1513-4de2-8468-29126af1193a","_cell_guid":"44bacabe-b023-4bba-9de9-500d219fefe5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-01T14:40:51.804281Z","iopub.execute_input":"2024-08-01T14:40:51.804675Z","iopub.status.idle":"2024-08-01T14:40:52.500995Z","shell.execute_reply.started":"2024-08-01T14:40:51.804641Z","shell.execute_reply":"2024-08-01T14:40:52.499848Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"t = pd.to_datetime('2017-07-05')\ntrain_start = []\nfor i in range(7):\n    delta = pd.Timedelta(days=7 * i)\n    train_start.append(t-delta)","metadata":{"_uuid":"ce21642b-02bf-4350-9654-2614f8a2b1c6","_cell_guid":"d688f9bf-9fbc-44fc-afad-2893f4035d20","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-01T14:40:55.447776Z","iopub.execute_input":"2024-08-01T14:40:55.448428Z","iopub.status.idle":"2024-08-01T14:40:55.456688Z","shell.execute_reply.started":"2024-08-01T14:40:55.448392Z","shell.execute_reply":"2024-08-01T14:40:55.454902Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_1=[]\ny_1=[]\nZ_1=[]\nfor start in train_start:\n \n    train_x,train_y=prepare_dataset(store_family,store_family_promo,start,columnname='store_family')\n   # Train.index=store_family.index\n   # Train=train_2.reindex(store_family_index.set_index(['store_nbr','family']).index).reset_index(drop=True)\n    \n    \n    train_1=prepare_dataset(family,family_promo,start,columnname='family',is_train=False)\n    train_1.index=family.index\n    train_1=train_1.reindex(sales_train.index.get_level_values(1)).reset_index(drop=True)\n    \n    train_all=pd.concat((train_x,train_1,stores.reset_index()),axis=1).fillna(0)\n   # Verticaltrain_all=pd.concat((train_x,train_1)).fillna(0)\n\n    X_1.append(train_all)\n    y_1.append(train_y)\n\n\nX_train=pd.concat(X_1,axis=0)\ny_train=np.concatenate(y_1,axis=0)","metadata":{"_uuid":"3fd3b3e7-4af1-488d-ae15-5a7fce9e187e","_cell_guid":"52de35bc-04ab-4b11-8ba8-a7daa4832e48","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-01T14:40:56.759102Z","iopub.execute_input":"2024-08-01T14:40:56.759464Z","iopub.status.idle":"2024-08-01T14:40:59.125221Z","shell.execute_reply.started":"2024-08-01T14:40:56.759439Z","shell.execute_reply":"2024-08-01T14:40:59.123898Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X_train= X_train[[i for i in X_train.columns if not 'proxy' in i]]\nvalidation= validation[[i for i in validation.columns if not 'proxy' in i]]\ntest= test[[i for i in test.columns if not 'proxy' in i]]","metadata":{"_uuid":"b72792d0-b6d1-48ab-bd61-7f27616bf8bc","_cell_guid":"19242e4f-4f07-4957-a123-b19d6f49c7bb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-01T14:40:59.127067Z","iopub.execute_input":"2024-08-01T14:40:59.127416Z","iopub.status.idle":"2024-08-01T14:40:59.144911Z","shell.execute_reply.started":"2024-08-01T14:40:59.127385Z","shell.execute_reply":"2024-08-01T14:40:59.143515Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def rmsle_lgbm(y_pred, data):\n\n    y_true = np.array(data.get_label())\n    \n    score = np.sqrt(np.mean(np.power(np.log1p(y_true) - np.log1p(y_pred), 2)))\n\n    return 'rmsle', score, False","metadata":{"_uuid":"270dd9b6-969b-4517-af27-17895ef6fa5e","_cell_guid":"c2edaa38-70df-4c88-829a-2bdce9d288cf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-01T14:40:59.146581Z","iopub.execute_input":"2024-08-01T14:40:59.146973Z","iopub.status.idle":"2024-08-01T14:40:59.155791Z","shell.execute_reply.started":"2024-08-01T14:40:59.146942Z","shell.execute_reply":"2024-08-01T14:40:59.154684Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error","metadata":{"_uuid":"adf65106-a162-4399-8187-db275c3e9107","_cell_guid":"bcc554fe-580d-45d8-a9da-580ef3e95de5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-01T14:41:00.320215Z","iopub.execute_input":"2024-08-01T14:41:00.320613Z","iopub.status.idle":"2024-08-01T14:41:01.225059Z","shell.execute_reply.started":"2024-08-01T14:41:00.320580Z","shell.execute_reply":"2024-08-01T14:41:01.223860Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"MAX_ROUNDS = 5000\n\nval_pred = []\ntest_pred = []\ncate_vars = []\n\nparams={\n    'objective': 'regression',\n    'learning_rate': 0.01,\n    'metric': 'custom',\n    'feature_fraction': 0.8,\n    'min_data_in_leaf': 150,\n     'n_jobs':-1,\n    'subsample':0.6        \n}\n\nfor i in range(16):\n    print('step %d' %(i+1))\n\n    \n    dtrain=lgb.Dataset(\n    X_train,label=y_train[:,i]\n    )\n    \n    dval=lgb.Dataset(\n    validation,label=val_y[:,i],reference=dtrain,\n    )\n    \n    bst= lgb.train(\n    params,dtrain,num_boost_round=MAX_ROUNDS,\n    valid_sets=[dtrain,dval],\n    callbacks=[lgb.early_stopping(150),lgb.log_evaluation(100)],\n    #early_stopping_rounds=125,verbose_eval=100,\n    feval=rmsle_lgbm)\n   # **callbacks=[lgb.early_stopping(stopping_rounds=150), lgb.log_evaluation(150)]**)\n    \n    \n   # print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n    #    zip(X_train.columns, bst.feature_importance(\"gain\")),\n     #   key=lambda x: x[1], reverse=True\n    #)))\n    \n\n    \n    val_pred.append(bst.predict(\n    validation,num_iteration=bst.best_iteration or MAX_ROUNDS\n    ))\n    \n    test_pred.append(bst.predict(\n    test, num_iteration=bst.best_iteration or MAX_ROUNDS\n    ))","metadata":{"_uuid":"d4a47cce-1dc4-4b9a-9a24-35392d3f8381","_cell_guid":"827507d5-b7c9-4934-9888-a41791bdf225","execution":{"iopub.status.busy":"2024-08-01T14:41:48.602296Z","iopub.execute_input":"2024-08-01T14:41:48.602685Z","iopub.status.idle":"2024-08-01T14:46:31.109701Z","shell.execute_reply.started":"2024-08-01T14:41:48.602654Z","shell.execute_reply":"2024-08-01T14:46:31.108449Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"step 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021948 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.515521\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.390449\tvalid_1's rmsle: 0.391512\n[200]\ttraining's rmsle: 0.233601\tvalid_1's rmsle: 0.235159\n[300]\ttraining's rmsle: 0.178764\tvalid_1's rmsle: 0.184366\n[400]\ttraining's rmsle: 0.162296\tvalid_1's rmsle: 0.17267\n[500]\ttraining's rmsle: 0.155663\tvalid_1's rmsle: 0.170776\n[600]\ttraining's rmsle: 0.151527\tvalid_1's rmsle: 0.170337\n[700]\ttraining's rmsle: 0.148049\tvalid_1's rmsle: 0.170462\nEarly stopping, best iteration is:\n[598]\ttraining's rmsle: 0.151613\tvalid_1's rmsle: 0.170318\nstep 2\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021436 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.466077\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.390475\tvalid_1's rmsle: 0.402654\n[200]\ttraining's rmsle: 0.23607\tvalid_1's rmsle: 0.246979\n[300]\ttraining's rmsle: 0.182551\tvalid_1's rmsle: 0.19503\n[400]\ttraining's rmsle: 0.166505\tvalid_1's rmsle: 0.182353\n[500]\ttraining's rmsle: 0.159934\tvalid_1's rmsle: 0.179479\n[600]\ttraining's rmsle: 0.155658\tvalid_1's rmsle: 0.178964\n[700]\ttraining's rmsle: 0.152083\tvalid_1's rmsle: 0.178895\n[800]\ttraining's rmsle: 0.148828\tvalid_1's rmsle: 0.179144\nEarly stopping, best iteration is:\n[687]\ttraining's rmsle: 0.152534\tvalid_1's rmsle: 0.178823\nstep 3\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021424 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.629209\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.396083\tvalid_1's rmsle: 0.408779\n[200]\ttraining's rmsle: 0.237709\tvalid_1's rmsle: 0.251276\n[300]\ttraining's rmsle: 0.180989\tvalid_1's rmsle: 0.198557\n[400]\ttraining's rmsle: 0.163956\tvalid_1's rmsle: 0.186484\n[500]\ttraining's rmsle: 0.156958\tvalid_1's rmsle: 0.183983\n[600]\ttraining's rmsle: 0.152258\tvalid_1's rmsle: 0.183523\n[700]\ttraining's rmsle: 0.148577\tvalid_1's rmsle: 0.18397\nEarly stopping, best iteration is:\n[587]\ttraining's rmsle: 0.152795\tvalid_1's rmsle: 0.183491\nstep 4\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020979 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.843972\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.384981\tvalid_1's rmsle: 0.432456\n[200]\ttraining's rmsle: 0.226713\tvalid_1's rmsle: 0.274608\n[300]\ttraining's rmsle: 0.16823\tvalid_1's rmsle: 0.217546\n[400]\ttraining's rmsle: 0.150729\tvalid_1's rmsle: 0.202133\n[500]\ttraining's rmsle: 0.144011\tvalid_1's rmsle: 0.198092\n[600]\ttraining's rmsle: 0.139881\tvalid_1's rmsle: 0.19669\n[700]\ttraining's rmsle: 0.136586\tvalid_1's rmsle: 0.196384\n[800]\ttraining's rmsle: 0.133677\tvalid_1's rmsle: 0.196505\nEarly stopping, best iteration is:\n[698]\ttraining's rmsle: 0.136642\tvalid_1's rmsle: 0.196374\nstep 5\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021114 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.838198\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.382758\tvalid_1's rmsle: 0.405467\n[200]\ttraining's rmsle: 0.227576\tvalid_1's rmsle: 0.250366\n[300]\ttraining's rmsle: 0.171095\tvalid_1's rmsle: 0.194961\n[400]\ttraining's rmsle: 0.154091\tvalid_1's rmsle: 0.180065\n[500]\ttraining's rmsle: 0.147048\tvalid_1's rmsle: 0.176786\n[600]\ttraining's rmsle: 0.142837\tvalid_1's rmsle: 0.176674\n[700]\ttraining's rmsle: 0.139472\tvalid_1's rmsle: 0.177239\nEarly stopping, best iteration is:\n[556]\ttraining's rmsle: 0.144522\tvalid_1's rmsle: 0.176457\nstep 6\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021517 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.547756\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.390902\tvalid_1's rmsle: 0.374998\n[200]\ttraining's rmsle: 0.234728\tvalid_1's rmsle: 0.23297\n[300]\ttraining's rmsle: 0.179828\tvalid_1's rmsle: 0.195071\n[400]\ttraining's rmsle: 0.163437\tvalid_1's rmsle: 0.189683\n[500]\ttraining's rmsle: 0.15675\tvalid_1's rmsle: 0.189509\nEarly stopping, best iteration is:\n[448]\ttraining's rmsle: 0.159723\tvalid_1's rmsle: 0.189358\nstep 7\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020932 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.507106\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.389861\tvalid_1's rmsle: 0.387271\n[200]\ttraining's rmsle: 0.234197\tvalid_1's rmsle: 0.239156\n[300]\ttraining's rmsle: 0.179272\tvalid_1's rmsle: 0.195631\n[400]\ttraining's rmsle: 0.162902\tvalid_1's rmsle: 0.186651\n[500]\ttraining's rmsle: 0.156055\tvalid_1's rmsle: 0.184865\n[600]\ttraining's rmsle: 0.151717\tvalid_1's rmsle: 0.184505\n[700]\ttraining's rmsle: 0.148242\tvalid_1's rmsle: 0.184806\nEarly stopping, best iteration is:\n[622]\ttraining's rmsle: 0.150896\tvalid_1's rmsle: 0.184459\nstep 8\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020799 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.516359\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.391297\tvalid_1's rmsle: 0.387359\n[200]\ttraining's rmsle: 0.2351\tvalid_1's rmsle: 0.239214\n[300]\ttraining's rmsle: 0.180094\tvalid_1's rmsle: 0.193896\n[400]\ttraining's rmsle: 0.163676\tvalid_1's rmsle: 0.184384\n[500]\ttraining's rmsle: 0.156811\tvalid_1's rmsle: 0.18274\n[600]\ttraining's rmsle: 0.152266\tvalid_1's rmsle: 0.182732\n[700]\ttraining's rmsle: 0.148589\tvalid_1's rmsle: 0.183\nEarly stopping, best iteration is:\n[558]\ttraining's rmsle: 0.154058\tvalid_1's rmsle: 0.182619\nstep 9\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.464279\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.392339\tvalid_1's rmsle: 0.388821\n[200]\ttraining's rmsle: 0.238324\tvalid_1's rmsle: 0.242677\n[300]\ttraining's rmsle: 0.185078\tvalid_1's rmsle: 0.199938\n[400]\ttraining's rmsle: 0.169425\tvalid_1's rmsle: 0.190962\n[500]\ttraining's rmsle: 0.162965\tvalid_1's rmsle: 0.189213\n[600]\ttraining's rmsle: 0.158577\tvalid_1's rmsle: 0.188959\n[700]\ttraining's rmsle: 0.154879\tvalid_1's rmsle: 0.188912\n[800]\ttraining's rmsle: 0.151567\tvalid_1's rmsle: 0.189115\nEarly stopping, best iteration is:\n[664]\ttraining's rmsle: 0.156214\tvalid_1's rmsle: 0.188807\nstep 10\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020810 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.592609\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.398323\tvalid_1's rmsle: 0.402962\n[200]\ttraining's rmsle: 0.239583\tvalid_1's rmsle: 0.252072\n[300]\ttraining's rmsle: 0.183525\tvalid_1's rmsle: 0.205074\n[400]\ttraining's rmsle: 0.166802\tvalid_1's rmsle: 0.19467\n[500]\ttraining's rmsle: 0.159809\tvalid_1's rmsle: 0.192033\n[600]\ttraining's rmsle: 0.155309\tvalid_1's rmsle: 0.191466\n[700]\ttraining's rmsle: 0.151662\tvalid_1's rmsle: 0.191257\n[800]\ttraining's rmsle: 0.148377\tvalid_1's rmsle: 0.191194\n[900]\ttraining's rmsle: 0.145298\tvalid_1's rmsle: 0.19128\nEarly stopping, best iteration is:\n[772]\ttraining's rmsle: 0.149254\tvalid_1's rmsle: 0.191132\nstep 11\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021478 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.844547\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.386945\tvalid_1's rmsle: 0.433068\n[200]\ttraining's rmsle: 0.228616\tvalid_1's rmsle: 0.282811\n[300]\ttraining's rmsle: 0.170431\tvalid_1's rmsle: 0.230426\n[400]\ttraining's rmsle: 0.153103\tvalid_1's rmsle: 0.213837\n[500]\ttraining's rmsle: 0.146377\tvalid_1's rmsle: 0.20872\n[600]\ttraining's rmsle: 0.142121\tvalid_1's rmsle: 0.20721\n[700]\ttraining's rmsle: 0.138769\tvalid_1's rmsle: 0.206458\n[800]\ttraining's rmsle: 0.135877\tvalid_1's rmsle: 0.206136\n[900]\ttraining's rmsle: 0.133166\tvalid_1's rmsle: 0.206097\n[1000]\ttraining's rmsle: 0.130629\tvalid_1's rmsle: 0.206044\n[1100]\ttraining's rmsle: 0.128261\tvalid_1's rmsle: 0.206026\n[1200]\ttraining's rmsle: 0.126018\tvalid_1's rmsle: 0.205996\n[1300]\ttraining's rmsle: 0.12383\tvalid_1's rmsle: 0.206007\nEarly stopping, best iteration is:\n[1185]\ttraining's rmsle: 0.126346\tvalid_1's rmsle: 0.205907\nstep 12\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020963 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.839905\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.38394\tvalid_1's rmsle: 0.398408\n[200]\ttraining's rmsle: 0.228479\tvalid_1's rmsle: 0.245659\n[300]\ttraining's rmsle: 0.171825\tvalid_1's rmsle: 0.192745\n[400]\ttraining's rmsle: 0.15491\tvalid_1's rmsle: 0.178331\n[500]\ttraining's rmsle: 0.147772\tvalid_1's rmsle: 0.174729\n[600]\ttraining's rmsle: 0.143571\tvalid_1's rmsle: 0.174222\n[700]\ttraining's rmsle: 0.140125\tvalid_1's rmsle: 0.174431\nEarly stopping, best iteration is:\n[583]\ttraining's rmsle: 0.144227\tvalid_1's rmsle: 0.174189\nstep 13\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021121 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.553681\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.390665\tvalid_1's rmsle: 0.373206\n[200]\ttraining's rmsle: 0.234428\tvalid_1's rmsle: 0.233528\n[300]\ttraining's rmsle: 0.17946\tvalid_1's rmsle: 0.196332\n[400]\ttraining's rmsle: 0.162967\tvalid_1's rmsle: 0.191152\n[500]\ttraining's rmsle: 0.156255\tvalid_1's rmsle: 0.189905\n[600]\ttraining's rmsle: 0.152\tvalid_1's rmsle: 0.189763\n[700]\ttraining's rmsle: 0.148455\tvalid_1's rmsle: 0.189684\n[800]\ttraining's rmsle: 0.145367\tvalid_1's rmsle: 0.189573\n[900]\ttraining's rmsle: 0.142491\tvalid_1's rmsle: 0.189463\n[1000]\ttraining's rmsle: 0.139881\tvalid_1's rmsle: 0.189489\nEarly stopping, best iteration is:\n[851]\ttraining's rmsle: 0.143902\tvalid_1's rmsle: 0.189425\nstep 14\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020773 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.506057\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.390855\tvalid_1's rmsle: 0.397649\n[200]\ttraining's rmsle: 0.23535\tvalid_1's rmsle: 0.252571\n[300]\ttraining's rmsle: 0.18053\tvalid_1's rmsle: 0.207787\n[400]\ttraining's rmsle: 0.164139\tvalid_1's rmsle: 0.197222\n[500]\ttraining's rmsle: 0.157402\tvalid_1's rmsle: 0.194537\n[600]\ttraining's rmsle: 0.15307\tvalid_1's rmsle: 0.194123\n[700]\ttraining's rmsle: 0.149625\tvalid_1's rmsle: 0.194188\nEarly stopping, best iteration is:\n[589]\ttraining's rmsle: 0.153478\tvalid_1's rmsle: 0.194087\nstep 15\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020959 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.501986\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.393412\tvalid_1's rmsle: 0.387222\n[200]\ttraining's rmsle: 0.236879\tvalid_1's rmsle: 0.246171\n[300]\ttraining's rmsle: 0.181778\tvalid_1's rmsle: 0.207913\n[400]\ttraining's rmsle: 0.165248\tvalid_1's rmsle: 0.201331\n[500]\ttraining's rmsle: 0.158537\tvalid_1's rmsle: 0.200085\n[600]\ttraining's rmsle: 0.154125\tvalid_1's rmsle: 0.199531\n[700]\ttraining's rmsle: 0.150369\tvalid_1's rmsle: 0.199306\n[800]\ttraining's rmsle: 0.147059\tvalid_1's rmsle: 0.199477\nEarly stopping, best iteration is:\n[696]\ttraining's rmsle: 0.150507\tvalid_1's rmsle: 0.199292\nstep 16\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021558 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 45531\n[LightGBM] [Info] Number of data points in the train set: 12474, number of used features: 205\n[LightGBM] [Info] Start training from score 3.452461\nTraining until validation scores don't improve for 150 rounds\n[100]\ttraining's rmsle: 0.393835\tvalid_1's rmsle: 0.386915\n[200]\ttraining's rmsle: 0.239422\tvalid_1's rmsle: 0.243393\n[300]\ttraining's rmsle: 0.185979\tvalid_1's rmsle: 0.203304\n[400]\ttraining's rmsle: 0.170169\tvalid_1's rmsle: 0.195413\n[500]\ttraining's rmsle: 0.163535\tvalid_1's rmsle: 0.193638\n[600]\ttraining's rmsle: 0.159245\tvalid_1's rmsle: 0.193201\n[700]\ttraining's rmsle: 0.15561\tvalid_1's rmsle: 0.192987\n[800]\ttraining's rmsle: 0.152293\tvalid_1's rmsle: 0.19315\nEarly stopping, best iteration is:\n[650]\ttraining's rmsle: 0.157388\tvalid_1's rmsle: 0.19292\n","output_type":"stream"}]},{"cell_type":"code","source":"q=rmsle_lgbm1(np.array(val_pred).transpose(),val_y)\n\nif q[1]<z:\n    print('improved')\n    z=q[1]\nelif q[1]>z:\n    print(\"increased error \")","metadata":{"_uuid":"c569163d-8fe5-4ae2-b4bc-e296a8dd8937","_cell_guid":"de47e8a0-b449-4e84-923e-004d390312b3","collapsed":false,"execution":{"iopub.status.busy":"2024-07-25T13:06:11.455683Z","iopub.execute_input":"2024-07-25T13:06:11.456109Z","iopub.status.idle":"2024-07-25T13:06:11.497072Z","shell.execute_reply.started":"2024-07-25T13:06:11.456078Z","shell.execute_reply":"2024-07-25T13:06:11.495496Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmsle_lgbm1(y_pred, y_true):\n\n   \n    score = np.sqrt(np.mean(np.power(np.log1p(y_true) - np.log1p(y_pred), 2)))\n\n    return 'rmsle', score, False","metadata":{"_uuid":"d6101ce1-3112-4593-96b3-73651e4a4e49","_cell_guid":"d07cb092-ab65-40ef-8611-f91e79a53d28","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-01T14:41:46.889257Z","iopub.execute_input":"2024-08-01T14:41:46.889615Z","iopub.status.idle":"2024-08-01T14:41:46.894930Z","shell.execute_reply.started":"2024-08-01T14:41:46.889589Z","shell.execute_reply":"2024-08-01T14:41:46.893888Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# # SUBMISSION","metadata":{"_uuid":"4207fc91-34d1-4154-acc8-e68075c9a3db","_cell_guid":"f9153ee0-1328-4c72-8650-bc2c622bb71a","trusted":true}},{"cell_type":"code","source":"y_test=np.array(test_pred).transpose()\npredictions=pd.DataFrame(\n    y_test,index=sales_train.index,\n    columns=pd.date_range(\"2017-08-16\",periods=16)\n).stack().to_frame(\"sales\")\n\npredictions.index.set_names(['store_nbr','family','date'],inplace=True)\n\ndf_test = pd.read_csv(r\"/kaggle/input/store-sales-time-series-forecasting/test.csv\"\n                  ).set_index(['store_nbr', 'family', 'date'])\n\nsubmission=df_test[['id']].join(predictions,how='left').fillna(0)\nsubmission[\"sales\"] = np.clip(np.expm1(submission[\"sales\"]), 0, 1000)\nsubmission.to_csv('lgb_sub.csv', float_format='%.4f', index=None)","metadata":{"_uuid":"15149d1f-3293-4748-8551-5364c0ca272c","_cell_guid":"33bed585-2b9d-48d9-8f14-f785bff400da","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-08-01T14:46:31.111717Z","iopub.execute_input":"2024-08-01T14:46:31.112162Z","iopub.status.idle":"2024-08-01T14:46:31.363295Z","shell.execute_reply.started":"2024-08-01T14:46:31.112121Z","shell.execute_reply":"2024-08-01T14:46:31.362276Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"7473f56e-1af7-44e3-b482-4a4d1c82fd3c","_cell_guid":"e22dc6a6-3254-4661-aeb8-21837e57bf2b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}